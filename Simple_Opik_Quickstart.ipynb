{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/statisticianinstilettos/Hackathon-Assets/blob/main/Simple_Opik_Quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting Starting with Opik for LLM Observability\n",
        "\n",
        "This example code is designed to help you get started with Comet Opik. It includes basic setup, and logging a trace from the Open AI API using Opik's integration and the @track decorator.\n"
      ],
      "metadata": {
        "id": "4nBkLEnK2yT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing our environment\n",
        "\n",
        "First, we will install the required libraries and set up our OpenAI API keys. Check out Opik config parameters here: https://www.comet.com/docs/opik/tracing/sdk_configuration"
      ],
      "metadata": {
        "id": "2eWfFnAJ4iRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U opik openai --quiet"
      ],
      "metadata": {
        "id": "m080q6EML_Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c366d8-99dd-495b-e640-3dfe5869a14f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.3/152.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m666.7/666.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.3/786.3 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for litellm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opik\n",
        "\n",
        "opik.configure(use_local=False)"
      ],
      "metadata": {
        "id": "7uIKdRLv5ueg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a91a914-e697-4e60-ba18-eb319bb0fb11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Your Opik API key is available in your account settings, can be found at https://www.comet.com/api/my/settings/ for Opik cloud\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Opik API key:··········\n",
            "Do you want to use \"statisticianinstilettos\" workspace? (Y/n)Y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Configuration saved to file: /root/.opik.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AjvhiY_4hug",
        "outputId": "64dfc5c7-d738-481b-e312-0ca9b8bd3610"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logging a Trace to Opik"
      ],
      "metadata": {
        "id": "aeC81nWGGcku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from opik import track, opik_context, Attachment\n",
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"quickstart-example\"\n",
        "\n",
        "client = OpenAI()\n",
        "openai_client = track_openai(client)"
      ],
      "metadata": {
        "id": "sXjEXs245jH2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from opik import track\n",
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "\n",
        "# Wrap your OpenAI client\n",
        "openai_client = OpenAI()\n",
        "openai_client = track_openai(openai_client)\n",
        "\n",
        "# Create your chain\n",
        "@track\n",
        "def llm_chain(input_text):\n",
        "    context = retrieve_context(input_text)\n",
        "    response = generate_response(input_text, context)\n",
        "    return response\n",
        "@track\n",
        "def retrieve_context(input_text):\n",
        "    # For the purpose of this example, we are just returning a hardcoded list of strings\n",
        "    context =[\n",
        "        \"What specific information are you looking for?\",\n",
        "        \"How can I assist you with your interests today?\",\n",
        "        \"Are there any topics you'd like to explore or learn more about?\",\n",
        "    ]\n",
        "    return context\n",
        "@track\n",
        "def generate_response(input_text, context):\n",
        "    full_prompt = (\n",
        "        f\" If the user asks a question that is not specific, use the context to provide a relevant response.\\n\"\n",
        "        f\"Context: {', '.join(context)}\\n\"\n",
        "        f\"User: {input_text}\\n\"\n",
        "        f\"AI:\"\n",
        "    )\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": full_prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "llm_chain(\"Hello, how are you?\")"
      ],
      "metadata": {
        "id": "dYlUJ--__Swy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "aa1ff19c-fe8c-43c2-80e9-581aa54f4bd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Started logging traces to the \"quickstart-example\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=01989620-9eac-70c8-8994-70a5982a8c6b&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! I am here to assist you with any specific information you may be looking for or any topics you would like to explore today. How can I help you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvv-OKLUF9lC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}